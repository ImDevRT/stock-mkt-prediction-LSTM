{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing required libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import quandl, math\n",
    "import datetime\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To plot within notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 20,10\n",
    "\n",
    "## for normalizing data (Feature normalization)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect the data and read the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('NSE-TATAGLOBAL.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Aqquirung the data\n",
    "#quandl.ApiConfig.api_key = '2sn6YtKZsAaoAdfyHzfX'\n",
    "#data = quandl.get('WIKI/FB')\n",
    "# Removing unnecessary data\n",
    "#data = data[['Adj. Open', 'Adj. High', 'Adj. Low', 'Adj. Close', 'Adj. Volume']];\n",
    "#print(data.head(10).round(1))\n",
    "#print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating dataframe with date and the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data = df.sort_index(ascending=True, axis=0)\n",
    "new_data = pd.DataFrame(index=range(0,len(df)),columns=['Date', 'Close'])\n",
    "\n",
    "# copying the Close value along with time into new dataframe\n",
    "for i in range(0,len(data)):\n",
    "     new_data['Date'][i] = data['Date'][i]\n",
    "     new_data['Close'][i] = data['Close'][i]\n",
    "\n",
    "new_data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting date as an index and droping the Date column\n",
    "new_data.index = new_data.Date\n",
    "new_data.drop('Date', axis=1, inplace=True)\n",
    "\n",
    "new_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Creating train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = new_data.values\n",
    "\n",
    "# spliting the dataset 0-987 in training set, rest in validation set\n",
    "train = dataset[0:987,:]\n",
    "valid = dataset[987:,:]\n",
    "\n",
    "print(\"Length of training data ->> \",len(train))\n",
    "print(\"Length of testing data ->> \",len(valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#converting dataset into x_train and y_train\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(dataset)\n",
    "\n",
    "x_train, y_train = [], []\n",
    "for i in range(60,len(train)):\n",
    "    x_train.append(scaled_data[i-60:i,0])\n",
    "    y_train.append(scaled_data[i,0])\n",
    "    \n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping the training data to add extra dimension for batch training purpose\n",
    "x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and fit the LSTM network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(x_train.shape[1],1)))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model training\n",
    "model.fit(x_train, y_train, epochs=1, batch_size=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# predicting 246 values, using past 60 from the train data\n",
    "inputs = new_data[len(new_data) - len(valid) - 60:].values\n",
    "inputs = inputs.reshape(-1,1)\n",
    "inputs  = scaler.transform(inputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Creating training rows (60 datapoints in one training row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_test = []\n",
    "for i in range(60,inputs.shape[0]):\n",
    "    X_test.append(inputs[i-60:i,0])\n",
    "X_test = np.array(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))\n",
    "closing_price = model.predict(X_test)\n",
    "closing_price = scaler.inverse_transform(closing_price)\n",
    "\n",
    "rms=np.sqrt(np.mean(np.power((valid-closing_price),2)))\n",
    "rms\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the predicated values along with original values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = new_data[:987]\n",
    "valid = new_data[987:]\n",
    "valid['Predictions'] = closing_price\n",
    "plt.plot(train['Close'])\n",
    "plt.plot(valid[['Close','Predictions']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
